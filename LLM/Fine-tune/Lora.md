Lora算法主要有以下几个关键技术细节:

1. 低秩分解表示法

Lora算法利用低秩分解来表示预训练模型权重矩阵在fine-tuning过程中所累积的梯度更新量。具体来说,对于预训练权重矩阵W∈R^{d×k},其累积更新量表示为:

ΔW = BA

其中B∈R^{d×r}, A∈R^{r×k}, r远小于d和k。这相当于用两个低秩矩阵B和A来近似表示ΔW。

这样一来,在fine-tuning过程中,只需要优化B和A两个低秩矩阵中的参数,而大量的预训练权重W则保持不变,从而极大减少了优化的参数量。

2. 前向传播过程

在Lora算法中,前向传播计算如下:

h = Wx + ΔWx
   = Wx + BAx

即用预训练权重W和低秩表示的ΔW分别对输入x进行变换,并将结果相加作为最终输出。

这样保持了预训练权重W不变,只通过学习B、A来完成特定任务的调整。

3. 参数初始化

在开始fine-tuning时,B初始化为0,A初始化为正态分布,即最开始ΔW=BA=0。然后通过缩放ΔWx来逐步增大其影响力。

4. 理论基础

Lora算法的设计基于以下理论:

(1) 神经网络在过参数化条件下,学习到的解往往具有低秩特性。

(2) fine-tuning过程中权重的变化也具有一定的低秩特性。

因此,用低秩分解来表示权重的更新量ΔW是合理的。

5. 实现细节

在Transformer中,可以只对self-attention模块的W_q, W_k, W_v等矩阵应用Lora。

实际实现中,为简化,只对W_q和W_v应用Lora。

总体而言,Lora提供了一种参数高效的神经网络微调方法,其关键是利用了低秩分解技术来表示权重更新量。这降低了模型调整到下游任务的计算和存储成本。