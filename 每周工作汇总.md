## 2.18-2.23



## 11.27-12.1

1. 8万篇 seq-英文 爬去到a800， 已经完成上传
2.  8万篇中吧PMC有的拉出来，再爬全文；已经正在爬取
3. Uniprot里面的蛋白质名构建一个搜索的关键词表：
	1. 构建初步完成，一共存在三种情况：
		- None: 现在Uniprot已经不存在该词条，可能为历史存在的词条，数量：381
		- recommended Name: 经过认证的protein name, 数量46626
		- submitted Name：还没有经过认证的，由提交信息自动生成的protein name，数量：63872-47007=
	1. 存在如下问题：
		1. 我们可以获取到的名字有两类：recommendedName；submittedName。这两种名字分别对应着是否经过审查；
		2. 我们获取到的protein name存在一定的问题：
		3. 


## 11.20-11.24

1. 中英文-已经存在，上传a800；
2. 8万篇 seq-英文 爬去到a800， 
3. 8万篇中吧PMC有的拉出来，再爬全文；
4. Uniprot里面的蛋白质名构建一个搜索的关键词表


## 10.23-10.29
1. Build the local development environment;
2. Using crawler to crawl open source papers from PMC database(next step: design keywords list);
3. 


## 10.16-10.22
1. We found two Chinese biology journals: Chinese journal of biotechnology and Chinese journal of cell biology.
2. If we need I think we can find about 20 journals that we can collect a sufficient corpus.

## 10.9-10.15 工作总结
1. 目前存在的问题主要有：我们的模型需要考虑输出多模态数据吗？公司是否具有现有的生成模型？
2. 将项目流程迁移到服务器上，和大家对接一下服务器的使用流程：
	- 比较显著的几个问题：
		- 可以在服务器里搭建自己的虚拟环境吗？
		- 项目在服务器上的同步路径


## 10.2-10.8 工作总结
1. 目前已经有数据样例，讨论后可以开始批量生成数据；
2. 详细讨论数据集的内部逻辑：我们需要多少的数据样本，我们的多模态数据应该就如同之前的论文[[2305.10688] MolXPT: Wrapping Molecules with Text for Generative Pre-training](https://arxiv.org/abs/2305.10688)一样，使用文本包裹分子。
3. 现在速度有点偏慢了，需要抓紧时间
4. 找到baseline，设计下游任务；
5. 对比他们的工作，他们是从头预训练了一个Model，然后再针对下游任务进行prompt fine-tuning。其中，他们对比的模型有Galactica：一个使用4800万篇论文、教科书和讲义、数以百万计的化合物和蛋白质、科学网站、百科全书以及来自"自然书"数据集的更多内容进行了训练的LLM，我觉得我们也可以考虑将其作为baseline。
6. 或者我们暂时将整个的目标放在比较低的位置上，例如我们只基于pretrained LLM针对下游任务进行fine-tune，例如文本-分子翻译任务等。

找graph的encoder LGN（GTA），sequence可以用esm。 instruction tuning

## 9.25-9.29 工作总结
1. 对接蛋白质结构图的表示方式
2. 对于蛋白质的各种特性的提取，是否具有倾向性？
3. 需要更多可以用于爬取论文的api的接入
4. 可以开始考虑如何搭建我们所需要的神经网络
5. 我们优先考虑的蛋白质数据集有哪些？使用哪一种蛋白质id？
6. 大语言模型调优手册 [GitHub - google-research/tuning\_playbook: A playbook for systematically maximizing the performance of deep learning models.](https://github.com/google-research/tuning_playbook#deep-learning-tuning-playbook)
7. 将数据注入到大语言模型的一个工具 [LlamaIndex - Data Framework for LLM Applications](https://www.llamaindex.ai/)

### 构建残基图遇到的问题
1. ~~生成文件夹的代码使用的是mkdir函数，只能生成单层文件夹~~（将文件夹生成函数改为makedirs）
2. 生成图时读取的pdb文件在dataset/SS_new文件夹中？
3. 生成图使用的pdb文件应该时什么样的？（pdb文件的命名方式？内部数据？）


## 9.18-9.22 工作总结

### 搭建论文信息提取的第二条技术路线：
当前只对每一个种类的蛋白质的每一篇文章进行多轮问答的数据集制作：
优点：可以详细的提取一篇文章中的大部分蛋白质相关内容，单篇论文内信息统一，不易形成不可信回答
缺点：单篇论文涉及的蛋白质信息片面，并且在蛋白质个数相当时可能会使得数据集体积过大，很有可能存在冗余（例如有1000个蛋白质，每一种蛋白质的论文选取10到20篇，每一篇会存在至少3个轮次的对话每轮约提出10个问题：在大语言模型完全会解答所有问题的情况下会存在300000到600000个单个问题的问答）
因此提出另一个技术路线：将同一种蛋白或一定量同族的蛋白放在一起，并将他们的论文（几十篇）放入一个数据库中，对该数据库进行多轮问答，提取出论文中的先验信息。

note：关于论文问答的问题，我认为可能需要专业的蛋白质方面专家进行一定的指导，我们会更关心蛋白质的部分方向的信息（例如我们如果目前只负责研究X蛋白质作为酶的性质，那么关于蛋白质如何天然的在某些生命体中自然合成过程这一信息就不需要，如果我们拿到的单篇蛋白质文章主要研究的方向就是这个，那么大语言模型提取出来的数据则会成为噪声）

BaiChuan 2
llama2
### 一些问题：
1. 在研究PPI的时候是否会产生限制（目前所有的论文提取只聚焦于了单个蛋白质的提取）；
2. 在第二轮问答时，虽然输入时会同时提出大量问题，但是回答模型只输出一个问题的答案；
3. 搭建论文信息提取的第二条技术路线，当前只对每一个种类的蛋白质的每一篇文章进行多轮问答的数据集制作：
4. 从pubmed直接提取出来的abstract也会存在一些噪声；比如段落开始到上角标前的文本会丢失，如下：
	- 原始数据：![[Pasted image 20230922140443.png]]
	- 从pubmed拿到的数据：
	  attributes={'Label': 'BACKGROUND'}), '3SA; phospholemman [FXYD1] in which the 3 phosphorylation sites on serines 63, 68, and 69 are mutated to alanines), 
5. 我在调取pubmed数据时，会将所有的
### 提出一些优化意见：
1. Nvidia有阅读文献的相关工具，可以尝试使用；
2. 

## 9.14-9.15 工作总结
1. 实现了两个模型的问答
2. 实现了在LangChain中同时调用condense prompt和自定义问题prompt
### 一些存在的问题
1. 问题会重复
2. 基于论文的提问会导致其大量的提问都围绕论文中的一些实际的操作，脱离了蛋白质本身的信息（理论上可以使用prompt控制，但是目前prompt较为脆弱，且控制能力较差），
3. 一篇论文所涉及的单纯蛋白质信息有限，是否需要考虑导入多篇论文只进行一次多轮问答。
4. 会出现提出了一串问题但是只回答了一个问题的情况发生。
5. 在研究PPI的时候是否会产生限制（目前所有的论文提取只聚焦于了单个蛋白质的提取）

## 9.13 工作总结
1. 是否应该使用文章进行问答，如何保证有逻辑的提出问题（能通过prompt控制吗？）
2. 问答的停止条件是什么？
3. Prompt设计正在进行。

## 9.12 工作总结
### 目前存在的问题：
1. 想要大语言模型提出问题则需要使用GPT-4，价格较为昂贵；
2. ~~是否需要给提问大语言模型整篇文章的先验知识；~~ 在使用文章问答的情况下，模型提出的问题会与文章形成强关联
3. 在微调大语言模型的过程中，文本数据使用论文提取出的多轮对话数据和直接使用大量的论文数据存在多大的差异（是否存在现成的评价体系？）；
4. ~~目前GPT4在蛋白质知识的广度上已经极其的优秀了，在没有论文先验的情况下，可以直接输出极大部分蛋白的浅层知识（对于深层蛋白质知识问答的情况不太在我的能力范围之内）。~~

## 8.29 ~ 9.5
### 完成部分：
1. 实现了对于单篇论文的处理；
2. 

## 7.25 ~ 7.31
### 完成部分：
1. 找到了一个程序，可以实现对于pdb文件的分析，其中包括了对于蛋白质序列的提取，蛋白质残基的CA之间的距离矩阵，主链夹角， 蛋白质残基链接图链长度。好改 [Bio.PDB package — Biopython 1.81 documentation](https://biopython.org/docs/latest/api/Bio.PDB.html)
2. 确定了基本的网络骨架 
3. 完成了数据集的图的绘制 pubmed claud

### 问题部分：
1. 如何测试和评价我们的模型，（可能要参考一些LLM的方法？）；需要和传统方法做比较吗？主观指标，客观问题，
3. 我们的related work应该怎么写？一些范例：写的很多的: ProGen2; 
4. 我们在chatPaper中需要提出的问题，每一篇论文的研究方向不一样，每一个蛋白质的作用域也不同，所属物种也不同，我们应该统一问题吗？
功能，

## 7.31 ~ 8.20
### 完成部分：
1. 针对所需要使用的PDF文件阅读，现在有如下几个选项: 
	1. 大型ai公司的api：
		1. 优点：可以批量化处理数据，可以较为自由的调试模型；对于claude，无法微调但是本身素质优秀，但是api申请暂时没有回应。
		2. 缺点：价格相对昂贵，并且对于PDF文件的数据预处理需要自己解决，prompt提示词需要自己慢慢尝试，一旦发现数据质量较低重新生成数据需要额外成本。
	2. DocGPT https://docgpt.io/web/viewer.html ：
		1. 优点：费用低，前三个月免费，之后每个月4.99刀；一次可以读取多个文件进行问答（暂时不确定其上下文长度）；有prompt辅助工具（也不知道有没有用）
		2. 缺点：没有api，难以批量化制作数据集。
2. 数据图像的绘制和颜色选择

util
pubmed






